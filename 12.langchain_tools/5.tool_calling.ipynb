{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16f869ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## Installing Libraries\n",
    "!pip install langchain langchain-core langchain-community langchain-huggingface requests -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f70338",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imorting necessary libraries\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain.agents import initialize_agent, Tool, tool\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_core.messages import HumanMessage\n",
    "import requests\n",
    "import json\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "742f1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a python tool \n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    '''Given two numbers a and b this tool returns their product'''\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "583c726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "multiply\n",
      "Given two numbers a and b this tool returns their product\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "## Tool testing\n",
    "print(multiply.invoke({'a' : 3, 'b' : 4}))\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d026e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing HuggingFace LLM\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= 'meta-llama/Llama-3.3-70B-Instruct'\n",
    ")\n",
    "\n",
    "## Initializing model\n",
    "model = ChatHuggingFace(llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eda3beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tool binding with LLM\n",
    "llm_with_tools = model.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c7f08",
   "metadata": {},
   "source": [
    "#### Method 1:  Conventional method - without tools calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653fe112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\": \"8\", \"b\": \"7\"}', 'name': 'multiply', 'description': None}, 'id': 'chatcmpl-tool-6a98c6c46a8447d2a1355b557d8e671a', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 204, 'total_tokens': 232}, 'model_name': 'meta-llama/Llama-3.3-70B-Instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--750c4453-6009-4b69-b7f9-f981389fec72-0', tool_calls=[{'name': 'multiply', 'args': {'a': '8', 'b': '7'}, 'id': 'chatcmpl-tool-6a98c6c46a8447d2a1355b557d8e671a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 204, 'output_tokens': 28, 'total_tokens': 232})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tool calling\n",
    "llm_with_tools.invoke(\"What is 8 multiplied by 7 ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9ca149a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': '8', 'b': '7'}\n"
     ]
    }
   ],
   "source": [
    "## Cleaning the call\n",
    "json_argument = json.loads(llm_with_tools.invoke(\"What is 8 multiplied by 7 ?\").additional_kwargs['tool_calls'][0]['function']['arguments'])\n",
    "print(json_argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e762012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Doing calculation\n",
    "multiply.invoke(json_argument)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db97fb9",
   "metadata": {},
   "source": [
    "#### Method 2:  Efficient method - with tools calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aa32bb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\": \"3\", \"b\": \"10\"}', 'name': 'multiply', 'description': None}, 'id': 'chatcmpl-tool-ec7dadf5971c40ae9f66d2fc9253726c', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 204, 'total_tokens': 232}, 'model_name': 'meta-llama/Llama-3.3-70B-Instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--6a57285c-cc11-4b74-92ef-192e73c04b5e-0', tool_calls=[{'name': 'multiply', 'args': {'a': '3', 'b': '10'}, 'id': 'chatcmpl-tool-ec7dadf5971c40ae9f66d2fc9253726c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 204, 'output_tokens': 28, 'total_tokens': 232})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tool calling\n",
    "response = llm_with_tools.invoke(\"Can you multiply 3 with 10?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5a937a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since the reposnse structure we are getting is incompatable to what langchain's invoke() method accepts, we are reconstructing a function by defining a new function:\n",
    "def extract_and_normalize_tool_call(response):\n",
    "    \"\"\"Extract the first tool call from LLM output and normalize it for LangChain invoke\"\"\"\n",
    "    tool_call_raw = response.additional_kwargs.get(\"tool_calls\", [])[0]\n",
    "\n",
    "    return {\n",
    "        \"name\": tool_call_raw[\"function\"][\"name\"],\n",
    "        \"args\": json.loads(tool_call_raw[\"function\"][\"arguments\"]),\n",
    "        \"description\": tool_call_raw[\"function\"].get(\"description\"),\n",
    "        \"id\": tool_call_raw[\"id\"],\n",
    "        \"type\": \"tool_call\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2b7d5255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply',\n",
       " 'args': {'a': '3', 'b': '10'},\n",
       " 'description': None,\n",
       " 'id': 'chatcmpl-tool-ec7dadf5971c40ae9f66d2fc9253726c',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting the required structured output from LLM\n",
    "structured_tool_call = extract_and_normalize_tool_call(response=response)\n",
    "structured_tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8467ba99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='30', name='multiply', tool_call_id='chatcmpl-tool-c2ad996a53544521834d0eb736e5ca9c')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke(structured_tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70623982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
