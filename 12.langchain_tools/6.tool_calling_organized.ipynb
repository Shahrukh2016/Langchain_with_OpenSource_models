{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16f869ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## Installing Libraries\n",
    "!pip install langchain langchain-core langchain-community langchain-huggingface requests -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90f70338",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imorting necessary libraries\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain.agents import initialize_agent, Tool, tool\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_core.messages import HumanMessage\n",
    "import requests\n",
    "import json\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "742f1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a python tool \n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    '''Given two numbers a and b this tool returns their product'''\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "583c726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "multiply\n",
      "Given two numbers a and b this tool returns their product\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "## Tool testing\n",
    "print(multiply.invoke({'a' : 3, 'b' : 4}))\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d026e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing HuggingFace LLM\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= 'meta-llama/Llama-3.3-70B-Instruct'\n",
    ")\n",
    "\n",
    "## Initializing model\n",
    "model = ChatHuggingFace(llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eda3beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tool binding with LLM\n",
    "llm_with_tools = model.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2522099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining a human message\n",
    "query = HumanMessage('Can you multiply 3 with 128 ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db300d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Can you multiply 3 with 128 ?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating a list that stores HumanMessage, AIMessage and ToolMessage that can be used for historical information and chatbot generation\n",
    "message = [query]\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa32bb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\": \"3\", \"b\": \"128\"}', 'name': 'multiply', 'description': None}, 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 204, 'total_tokens': 226}, 'model_name': 'meta-llama/Llama-3.3-70B-Instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4add37cb-f3f6-433f-aff2-6344ef589868-0', tool_calls=[{'name': 'multiply', 'args': {'a': '3', 'b': '128'}, 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770', 'type': 'tool_call'}], usage_metadata={'input_tokens': 204, 'output_tokens': 22, 'total_tokens': 226})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tool calling\n",
    "response = llm_with_tools.invoke(message)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8fe1d8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Can you multiply 3 with 128 ?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\": \"3\", \"b\": \"128\"}', 'name': 'multiply', 'description': None}, 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 204, 'total_tokens': 226}, 'model_name': 'meta-llama/Llama-3.3-70B-Instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4add37cb-f3f6-433f-aff2-6344ef589868-0', tool_calls=[{'name': 'multiply', 'args': {'a': '3', 'b': '128'}, 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770', 'type': 'tool_call'}], usage_metadata={'input_tokens': 204, 'output_tokens': 22, 'total_tokens': 226})]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Appending the AIMessage into the aobve defined list\n",
    "message.append(response)\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a937a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since the reposnse structure we are getting is incompatable to what langchain's invoke() method accepts, we are reconstructing a function by defining a new function:\n",
    "def extract_and_normalize_tool_call(response):\n",
    "    \"\"\"Extract the first tool call from LLM output and normalize it for LangChain invoke\"\"\"\n",
    "    tool_call_raw = response.additional_kwargs.get(\"tool_calls\", [])[0]\n",
    "\n",
    "    return {\n",
    "        \"name\": tool_call_raw[\"function\"][\"name\"],\n",
    "        \"args\": json.loads(tool_call_raw[\"function\"][\"arguments\"]),\n",
    "        \"description\": tool_call_raw[\"function\"].get(\"description\"),\n",
    "        \"id\": tool_call_raw[\"id\"],\n",
    "        \"type\": \"tool_call\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b7d5255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply',\n",
       " 'args': {'a': '3', 'b': '128'},\n",
       " 'description': None,\n",
       " 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting the required structured output from LLM\n",
    "structured_tool_call = extract_and_normalize_tool_call(response=response)\n",
    "structured_tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8467ba99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='384', name='multiply', tool_call_id='chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sending to LLM and getting the output\n",
    "tool_result = multiply.invoke(structured_tool_call)\n",
    "tool_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70623982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Can you multiply 3 with 128 ?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\": \"3\", \"b\": \"128\"}', 'name': 'multiply', 'description': None}, 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 204, 'total_tokens': 226}, 'model_name': 'meta-llama/Llama-3.3-70B-Instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4add37cb-f3f6-433f-aff2-6344ef589868-0', tool_calls=[{'name': 'multiply', 'args': {'a': '3', 'b': '128'}, 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770', 'type': 'tool_call'}], usage_metadata={'input_tokens': 204, 'output_tokens': 22, 'total_tokens': 226}),\n",
       " ToolMessage(content='384', name='multiply', tool_call_id='chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Appending the ToolMessage into the aobve defined list\n",
    "message.append(tool_result)\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef3eea08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This JSON function call will multiply 3 and 128, returning their product, which is 384.\n"
     ]
    }
   ],
   "source": [
    "## We have maintained the entire chat history that helps us to call and evaluate the calculation using the tool, now we just need to pass the entire message thread to the LLM and get the response back.\n",
    "final_result = llm_with_tools.invoke(message)\n",
    "print(final_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac1b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
