{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcdd8b36",
   "metadata": {},
   "source": [
    "In this project we need to convert the given input currency into the desired currency.\n",
    "\n",
    "We will do this in 2 steps:\n",
    "1. Tool 1: It will find the real time conversion factor.\n",
    "2. Tool 2: It will calulcate the result by multiplying the real time conversion factor with the given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f869ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## Installing Libraries\n",
    "!pip install langchain langchain-core langchain-community langchain-huggingface requests -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90f70338",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imorting necessary libraries\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain.agents import tool\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_core.messages import HumanMessage\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e5a35",
   "metadata": {},
   "source": [
    "#### Step 1: Tool Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "742f1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a python tool \n",
    "from langchain_core.tools import InjectedToolArg\n",
    "from typing import Annotated\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    '''This function takes 2 input a and b and find the product between them'''\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    '''This function takes 2 input a and b and find the summation between them'''\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def division(a: int, b: int) -> int:\n",
    "    '''This function takes 2 input a and b and find the division between them'''\n",
    "    return a / b\n",
    "\n",
    "@tool\n",
    "def substraction(a: int, b: int) -> int:\n",
    "    '''This function takes 2 input a and b and find the substraction between them'''\n",
    "    return a - b\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73031b7f",
   "metadata": {},
   "source": [
    "#### Step 2: Tool Binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d03c4fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Desktop\\LangChain\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatHuggingFace(llm=HuggingFaceEndpoint(repo_id='moonshotai/Kimi-K2-Instruct', huggingfacehub_api_token='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', stop_sequences=[], server_kwargs={}, model_kwargs={}, model='moonshotai/Kimi-K2-Instruct', client=<InferenceClient(model='moonshotai/Kimi-K2-Instruct', timeout=120)>, async_client=<InferenceClient(model='moonshotai/Kimi-K2-Instruct', timeout=120)>), model_id='moonshotai/Kimi-K2-Instruct', model_kwargs={}), kwargs={'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'This function takes 2 input a and b and find the product between them', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'This function takes 2 input a and b and find the summation between them', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'division', 'description': 'This function takes 2 input a and b and find the division between them', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'substraction', 'description': 'This function takes 2 input a and b and find the substraction between them', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tool Binding\n",
    "\n",
    "# Initializing HuggingFace LLM\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= 'moonshotai/Kimi-K2-Instruct'\n",
    ")\n",
    "\n",
    "## Initializing model\n",
    "model = ChatHuggingFace(llm = llm)\n",
    "\n",
    "# Bind the LLM with the above definded tools\n",
    "llm_with_tools = model.bind_tools([multiply, add, division, substraction])\n",
    "llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d682097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'multiply',\n",
       "   'description': 'This function takes 2 input a and b and find the product between them',\n",
       "   'parameters': {'properties': {'a': {'type': 'integer'},\n",
       "     'b': {'type': 'integer'}},\n",
       "    'required': ['a', 'b'],\n",
       "    'type': 'object'}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'add',\n",
       "   'description': 'This function takes 2 input a and b and find the summation between them',\n",
       "   'parameters': {'properties': {'a': {'type': 'integer'},\n",
       "     'b': {'type': 'integer'}},\n",
       "    'required': ['a', 'b'],\n",
       "    'type': 'object'}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'division',\n",
       "   'description': 'This function takes 2 input a and b and find the division between them',\n",
       "   'parameters': {'properties': {'a': {'type': 'integer'},\n",
       "     'b': {'type': 'integer'}},\n",
       "    'required': ['a', 'b'],\n",
       "    'type': 'object'}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'substraction',\n",
       "   'description': 'This function takes 2 input a and b and find the substraction between them',\n",
       "   'parameters': {'properties': {'a': {'type': 'integer'},\n",
       "     'b': {'type': 'integer'}},\n",
       "    'required': ['a', 'b'],\n",
       "    'type': 'object'}}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.kwargs['tools']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ba07ea",
   "metadata": {},
   "source": [
    "#### Step 3: Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c28f613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining a object message that stores all the chat including HumanMessage, AIMessage and ToolMessage so that calculations can be done using defined tools.\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79b35560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the value of 5 / 7 and 6 * 2?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating the human message\n",
    "human_message = HumanMessage('What is the value of 5 / 7 and 6 * 2?')\n",
    "messages.append(human_message)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "468a051f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the value of 5 / 7 and 6 * 2?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'll calculate both values for you.\", additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\": 5, \"b\": 7}', 'name': 'division', 'description': None}, 'id': 'division:0', 'type': 'function'}, {'function': {'arguments': '{\"a\": 6, \"b\": 2}', 'name': 'multiply', 'description': None}, 'id': 'multiply:1', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 259, 'total_tokens': 307}, 'model_name': 'moonshotai/Kimi-K2-Instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5d106bda-ab15-4a5a-9160-67ff065a1423-0', tool_calls=[{'name': 'division', 'args': {'a': 5, 'b': 7}, 'id': 'division:0', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 6, 'b': 2}, 'id': 'multiply:1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 259, 'output_tokens': 48, 'total_tokens': 307})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating the AI message\n",
    "ai_message = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_message)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "653dc535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'division',\n",
       "  'args': {'a': 5, 'b': 7},\n",
       "  'id': 'division:0',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'multiply',\n",
       "  'args': {'a': 6, 'b': 2},\n",
       "  'id': 'multiply:1',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7b699379",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since the reposnse structure we are getting is incompatable to what langchain's invoke() method accepts, we are reconstructing a function by defining a new function:\n",
    "def extract_and_normalize_tool_call(response):\n",
    "    \"\"\"Extract the first tool call from LLM output and normalize it for LangChain invoke\"\"\"\n",
    "    tool_call_raw = response.additional_kwargs.get(\"tool_calls\", [])[0]\n",
    "\n",
    "    return {\n",
    "        \"name\": tool_call_raw[\"function\"][\"name\"],\n",
    "        \"args\": json.loads(tool_call_raw[\"function\"][\"arguments\"]),\n",
    "        \"description\": tool_call_raw[\"function\"].get(\"description\"),\n",
    "        \"id\": tool_call_raw[\"id\"],\n",
    "        \"type\": \"tool_call\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c28effa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tool_calls': [{'function': {'arguments': '{\"base_currency\": \"USD\", \"target_currency\": \"INR\"}', 'name': 'get_conversion_factor', 'description': None}, 'id': 'call_2bba6fafec08fe78', 'type': 'function'}]}\n"
     ]
    }
   ],
   "source": [
    "print(ai_message.additional_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109754ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the conversion factor between USD to INR, and based on that can you convert 10 usd to inr', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"base_currency\": \"USD\", \"target_currency\": \"INR\"}', 'name': 'get_conversion_factor', 'description': None}, 'id': 'chatcmpl-tool-e49c23cdf15c4ac98b852b7d2563b461', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 347, 'total_tokens': 380}, 'model_name': 'meta-llama/Llama-3.3-70B-Instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2deedabd-6597-4f2b-9e05-b856e7e0d2cd-0', tool_calls=[{'name': 'get_conversion_factor', 'args': {'base_currency': 'USD', 'target_currency': 'INR'}, 'id': 'chatcmpl-tool-e49c23cdf15c4ac98b852b7d2563b461', 'type': 'tool_call'}], usage_metadata={'input_tokens': 347, 'output_tokens': 33, 'total_tokens': 380}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"base_currency_value\": \"10\", \"conversion_rate\": {\"function_name\": \"get_conversion_factor\", \"args\": [\"USD\", \"INR\"]}}', 'name': 'convert', 'description': None}, 'id': 'chatcmpl-tool-af1dde9d6afa4dcc8e7c1b78ed1d3509', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 378, 'total_tokens': 421}, 'model_name': 'meta-llama/Llama-3.3-70B-Instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a0a32d04-633f-4e3a-b4b1-574180b60a09-0', tool_calls=[{'name': 'convert', 'args': {'base_currency_value': '10', 'conversion_rate': {'function_name': 'get_conversion_factor', 'args': ['USD', 'INR']}}, 'id': 'chatcmpl-tool-af1dde9d6afa4dcc8e7c1b78ed1d3509', 'type': 'tool_call'}], usage_metadata={'input_tokens': 378, 'output_tokens': 43, 'total_tokens': 421})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating the Tool message\n",
    "tool_message = llm_with_tools.invoke(message)\n",
    "message.append(tool_message)\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2373e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837efaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbad9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e5cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "583c726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "multiply\n",
      "Given two numbers a and b this tool returns their product\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "## Tool testing\n",
    "print(multiply.invoke({'a' : 3, 'b' : 4}))\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d026e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing HuggingFace LLM\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= 'meta-llama/Llama-3.3-70B-Instruct'\n",
    ")\n",
    "\n",
    "## Initializing model\n",
    "model = ChatHuggingFace(llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eda3beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tool binding with LLM\n",
    "llm_with_tools = model.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2522099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining a human message\n",
    "query = HumanMessage('Can you multiply 3 with 128 ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db300d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Can you multiply 3 with 128 ?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating a list that stores HumanMessage, AIMessage and ToolMessage that can be used for historical information and chatbot generation\n",
    "message = [query]\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa32bb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\": \"3\", \"b\": \"128\"}', 'name': 'multiply', 'description': None}, 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 204, 'total_tokens': 226}, 'model_name': 'meta-llama/Llama-3.3-70B-Instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4add37cb-f3f6-433f-aff2-6344ef589868-0', tool_calls=[{'name': 'multiply', 'args': {'a': '3', 'b': '128'}, 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770', 'type': 'tool_call'}], usage_metadata={'input_tokens': 204, 'output_tokens': 22, 'total_tokens': 226})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tool calling\n",
    "response = llm_with_tools.invoke(message)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8fe1d8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Can you multiply 3 with 128 ?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\": \"3\", \"b\": \"128\"}', 'name': 'multiply', 'description': None}, 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 204, 'total_tokens': 226}, 'model_name': 'meta-llama/Llama-3.3-70B-Instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4add37cb-f3f6-433f-aff2-6344ef589868-0', tool_calls=[{'name': 'multiply', 'args': {'a': '3', 'b': '128'}, 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770', 'type': 'tool_call'}], usage_metadata={'input_tokens': 204, 'output_tokens': 22, 'total_tokens': 226})]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Appending the AIMessage into the aobve defined list\n",
    "message.append(response)\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a937a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since the reposnse structure we are getting is incompatable to what langchain's invoke() method accepts, we are reconstructing a function by defining a new function:\n",
    "def extract_and_normalize_tool_call(response):\n",
    "    \"\"\"Extract the first tool call from LLM output and normalize it for LangChain invoke\"\"\"\n",
    "    tool_call_raw = response.additional_kwargs.get(\"tool_calls\", [])[0]\n",
    "\n",
    "    return {\n",
    "        \"name\": tool_call_raw[\"function\"][\"name\"],\n",
    "        \"args\": json.loads(tool_call_raw[\"function\"][\"arguments\"]),\n",
    "        \"description\": tool_call_raw[\"function\"].get(\"description\"),\n",
    "        \"id\": tool_call_raw[\"id\"],\n",
    "        \"type\": \"tool_call\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b7d5255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply',\n",
       " 'args': {'a': '3', 'b': '128'},\n",
       " 'description': None,\n",
       " 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting the required structured output from LLM\n",
    "structured_tool_call = extract_and_normalize_tool_call(response=response)\n",
    "structured_tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8467ba99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='384', name='multiply', tool_call_id='chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sending to LLM and getting the output\n",
    "tool_result = multiply.invoke(structured_tool_call)\n",
    "tool_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70623982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Can you multiply 3 with 128 ?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\": \"3\", \"b\": \"128\"}', 'name': 'multiply', 'description': None}, 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770', 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 204, 'total_tokens': 226}, 'model_name': 'meta-llama/Llama-3.3-70B-Instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4add37cb-f3f6-433f-aff2-6344ef589868-0', tool_calls=[{'name': 'multiply', 'args': {'a': '3', 'b': '128'}, 'id': 'chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770', 'type': 'tool_call'}], usage_metadata={'input_tokens': 204, 'output_tokens': 22, 'total_tokens': 226}),\n",
       " ToolMessage(content='384', name='multiply', tool_call_id='chatcmpl-tool-ad3021a52c334b9ea61450b2726cb770')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Appending the ToolMessage into the aobve defined list\n",
    "message.append(tool_result)\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef3eea08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This JSON function call will multiply 3 and 128, returning their product, which is 384.\n"
     ]
    }
   ],
   "source": [
    "## We have maintained the entire chat history that helps us to call and evaluate the calculation using the tool, now we just need to pass the entire message thread to the LLM and get the response back.\n",
    "final_result = llm_with_tools.invoke(message)\n",
    "print(final_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac1b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
